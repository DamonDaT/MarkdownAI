### 【一】文档介绍

***

> 随着 NLP 和 LLM 的快速发展，各个细分领域里的模型评测数据集层出不穷，这里挑重点的主流的记录下



***



### 【二】NLU 自然语言理解

***

> 自然语言理解，该领域的数据集最为常见



#### 【2.1】GLUE

***

> General Language Understanding Evaluation (GLUE) Benchmark：用于对英文自然语言理解（NLU）任务进行训练，校验和测试的数据集

> https://huggingface.co/datasets/nyu-mll/glue



##### 【2.1.1】自然语言推理（NLI）

***

> 给定句子，将自然语言推理任务转化为分类任务

**ax**：该数据集适用于自然语言理解中的推理（NLI）任务，可使用在 MultiNLI 上训练的模型来针对此数据集进行后续预测校验。

**mnli /mnli_matched / mnli_mismatched**（蕴含，矛盾，中立）：语料是众包方式对句子进行 **文本蕴含** 注释。语料给定一个 **前提句子** 和一个 假设句子，任务内容是预测前提句子和假设句子是否逻辑相容（蕴含，矛盾，中立）。前提句来自于十种不同的语料来源，包括转录的演讲、小说、官方报告等。

**rte**（蕴含，不蕴含）：从 RTE1、RTE2、RTE3、RTE5 等多个年度 **文本蕴含** 挑战赛数据集整合而来的，其语料来源是新闻和百科。作者将原来的三分类转换为二分类任务，合并了中立和矛盾，并将标签设置为不蕴含。



##### 【2.1.2】语义相似度（SS）

***

> 给定句子，判断句子在语义上是否相似，或者推断相似度得分，也是分类任务

**mrpc**（相似，不相似）：语料来自于线上新闻，经过人工标注的双句，进行语义相似度（有关 / 无关）判断的数据集。

**qqp**（相似，不相似）：预料来自 Quora，给定一个前提句子和一个假设句子，判断这两个句子在语义上是否相似。

**stsb**（得分 (从1到5) ）：语料来源是新闻、视频、图片标题等提取的句子对集合，并进行了人工标注。每个句子对标注了相似度得分（从1到5）。



##### 【2.1.3】其他分类任务

***

> 从其他角度入手的分类任务，包括语法正确性，问答逻辑，情感分类，指代替换

**cola**（语法正确性）：语料库由来自语言理论书籍和期刊文章的英语可接受性判断组成。每个示例都是一个单词序列，并标注是否是符合语法的英语句子。

**qnli**（问答逻辑）：来自于 SQuAD 数据集，后者是一个问答数据集，整个段落中的一句话包含了该问题的答案，模型要求将该答案句子从问题中预测出来。本数据集的作者过滤掉了上述问答句子之间词汇重叠较低的句子对，然后将该问答任务转换为双句分类任务，句子中的一个是问题，另一个是答案，本数据集预测两个句子是否存在问答逻辑。

**sst2**（情感分类）：来自于电影的评论信息，并人工标注了它们的情感倾向。该数据集用于做单句双标签的情感分析任务。

**wnli**（指代替换）：WNLI 是一个自然语言推断任务数据集。用该数据集测试的模型读入有代词的句子，并从一个列表中正确地选择出该代词指代的对象。这些句子是手动构建的，以避免简单统计方式对此任务的有效性：每个代词都取决于单个单词或短语提供的上下文信息。为了将该问题转换为双句分类问题，作者将原句中模棱两可的代词以每个可能的指代替换并构造双句，该任务需要预测这些代词被替换的句子是否被原句子蕴含。作者提供了一个小的测试集，其语料是原始数据集中私下共享的小说部分的一些新的示例。训练集的两个分类语料是均衡的，但测试集不是均衡的（65%的蕴含语料）。另外，验证集是对抗性的：'假设句子'有时候同时出现在训练和验证集中，因此一个模型如果记住了训练语料，它有可能在校验语料中预测出一个错误的标签。和QNLI相同，每个样例是单独评估的，因此模型在此任务的得分和原始任务的得分没有系统性对应关系。



### 【三】Text-to-Code 文本到代码

***

> 由于在工作项目中接触这块比较多，而且随着 LLM 的发展，代码生成也在飞快的迭代更新，这里梳理下



#### 【3.1】OpenAI HumanEval

***

> 来自 OpenAI，包含 164 个样本，基于 Python 和英文自然语言手动构建

> https://huggingface.co/datasets/openai_humaneval



#### 【3.2】Google MBPP

***





#### 【3.1】Stanford Alpaca 7B

***

> 来自斯坦福大学，基于合成数据（使用 textdavinci-003 生成）进行指令微调，随后这种造数据的方式火起来了

<img src="./images/LLaMA/11.jpg"> 

**初衷**：像 GPT-3.5（text-davinci-003）、ChatGPT、Claude 和 Bing Chat 这样的 **指令跟随（Instruction-following ）**模型变得越来越强大. 现在许多用户经常与这些模互动，甚至将它们用于工作. 然而，尽管广泛部署，指令跟随模型仍然存在许多不足之处：它们可能生成虚假信息、传播社会刻板印象并产生有毒语言.

**Alpaca** 是一个指令跟随语言模型，从 **Meta‘s LLaMA 7B** 模型微调而来. 使用以 textdavinci-003 风格自我指导（selfinstruct）生成的 52K 个指令跟随演示来训练Alpaca 模型. 在自我指导评估数据集上，Alpaca 表现出许多类似于 OpenAI text-davinci-003 的行为，并且惊人地小巧、易于复制和廉价（不到600美金）.

***



#### 【3.2】Vicuna 13B

***

> 来自多家研究机构（UC Berkeley，CMU，斯坦福，US San Dego 和 MBZUAI），基于对话数据

<img src="./images/LLaMA/12.jpg"> 

**Vicuna** 是在 LLaMa 1-13B 的基础上使用监督数据微调得到的模型，数据集来自于 **ShareGPT** 产生的 70K 条用户对话数据，增强了 Alpaca 提供的训练脚本，以更好地处理多轮对话和长序列. 相较于Alpaca，Vicuna 在训练中将序列长度由 512 扩展到了 **2048**，并且通过 梯度检测 和 **flash attention** 来解决显存问题；针对多轮对话来调整训练损失，并仅根据模型的输出进行微调. 通过 **GPT4** 来打分评测，Vicuna 可以达到 **ChatGPT 90%** 的效果.

***



### 【四】LLaMA-2

***

> Meta 在 LLaMA 1 发布后，时隔半年推出第二代 LLaMA，大名鼎鼎的 **LLaMA-2**



#### 【4.1】与 LLaMA 1 对比

> 长文本，更多的训练数据（2 万亿 token）

<img src="./images/LLaMA/13.jpg">  

***



#### 【4.2】LLaMA 2 - Chat 训练方法

***

> 在 **100** **万人类标记数据** 上进行 **RLHF** 训练得到 **LLaMA 2-Chat** 模型

<img src="./images/LLaMA/14.jpg"> 

***



#### 【4.3】CodeLlama

***

